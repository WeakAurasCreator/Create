name: Gather Static WoW data

on:
  schedule:
    - cron: '0 0 * * WED'
  workflow_dispatch:

jobs:
  gather-items:
    runs-on: ubuntu-latest
    env:
      BLIZZARD_CLIENT_ID: ${{ secrets.BLIZZARD_CLIENT_ID }}
      BLIZZARD_CLIENT_SECRET: ${{ secrets.BLIZZARD_CLIENT_SECRET }}
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install pandas
        run: pip install pandas

      - name: Create data directory
        run: mkdir -p data

      - name: Download CSV files
        run: |
          curl -L "https://wago.tools/db2/JournalEncounter/csv?product=wow" -o data/JournalEncounter.csv
          curl -L "https://wago.tools/db2/JournalInstance/csv?product=wow" -o data/JournalInstance.csv
          curl -L "https://wago.tools/db2/JournalTierXInstance/csv?product=wow" -o data/JournalTierXInstance.csv
          curl -L "https://wago.tools/db2/JournalTier/csv?product=wow" -o data/JournalTier.csv
          curl -L "https://wago.tools/db2/JournalSectionXDifficulty/csv?product=wow" -o data/JournalSectionXDifficulty.csv
          curl -L "https://wago.tools/db2/Difficulty/csv?product=wow" -o data/Difficulty.csv
          curl -L "https://www.raidbots.com/static/data/live/metadata.json" -o data/metadata.json
          curl -L "https://www.raidbots.com/static/data/live/equippable-items.json" -o data/equippable-items.json


      - name: Convert CSVs to JSON
        run: |
          python - <<'EOF'
          import pandas as pd
          import json

          def process_journal_encounter():
              df = pd.read_csv('data/JournalEncounter.csv')
              df = df.where(pd.notnull(df), None)
              # Create a custom key: Name_lang(DungeonEncounterID)
              df['custom_key'] = df['Name_lang'] + '(' + df['DungeonEncounterID'].astype(str) + ')'
              # Group by custom_key and drop the custom_key column from each group to avoid deprecation warnings
              grouped = df.groupby('custom_key', group_keys=False).apply(lambda x: x.drop(columns=['custom_key']).to_dict('records')).to_dict()
              with open('data/JournalEncounter.json', 'w') as f:
                  json.dump(grouped, f, indent=4, allow_nan=False)

          def process_journal_instance():
              df = pd.read_csv('data/JournalInstance.csv')
              df = df.where(pd.notnull(df), None)
              df.set_index('ID', inplace=True)
              df.to_json('data/JournalInstance.json', orient='index', indent=4)

          def process_journal_tier_x_instance():
              df = pd.read_csv('data/JournalTierXInstance.csv')
              df = df.where(pd.notnull(df), None)
              # Group by JournalInstanceID and drop the grouping column from each group.
              grouped = df.groupby('JournalInstanceID', group_keys=False).apply(lambda x: x.drop(columns=['JournalInstanceID']).to_dict('records')).to_dict()
              with open('data/JournalTierXInstance.json', 'w') as f:
                  json.dump(grouped, f, indent=4, allow_nan=False)

          def process_journal_tier():
              df = pd.read_csv('data/JournalTier.csv')
              df = df.where(pd.notnull(df), None)
              df.set_index('ID', inplace=True)
              df.to_json('data/JournalTier.json', orient='index', indent=4)

          def process_journal_section_x_difficulty():
              df = pd.read_csv('data/JournalSectionXDifficulty.csv')
              df = df.where(pd.notnull(df), None)
              # Group by JournalEncounterSectionID and drop it from each group's records.
              grouped = df.groupby('JournalEncounterSectionID', group_keys=False).apply(lambda x: x.drop(columns=['JournalEncounterSectionID']).to_dict('records')).to_dict()
              with open('data/JournalSectionXDifficulty.json', 'w') as f:
                  json.dump(grouped, f, indent=4, allow_nan=False)

          def process_difficulty():
              df = pd.read_csv('data/Difficulty.csv')
              df = df.where(pd.notnull(df), None)
              df.set_index('ID', inplace=True)
              df.to_json('data/Difficulty.json', orient='index', indent=4)

          process_journal_encounter()
          process_journal_instance()
          process_journal_tier_x_instance()
          process_journal_tier()
          process_journal_section_x_difficulty()
          process_difficulty()
          EOF
      
      - name: Download WoW item icons
        run: |
          python - <<'EOF'
          import os
          import json
          import urllib.request
          import urllib.error
          from concurrent.futures import ThreadPoolExecutor, as_completed

          # Load items
          with open('data/equippable-items.json', 'r') as f:
              items = json.load(f)

          # Unique icon names
          icons = {item.get('icon') for item in items if item.get('icon')}

          # Ensure output directory exists
          os.makedirs('data/icons', exist_ok=True)

          # Download function
          def download_icon(icon_name):
              url = f'https://render.worldofwarcraft.com/eu/icons/56/{icon_name}.jpg'
              dest = f'data/icons/{icon_name}.jpg'
              try:
                  urllib.request.urlretrieve(url, dest)
                  return f"Downloaded: {icon_name}"
              except urllib.error.HTTPError as e:
                  return f"Failed ({e.code}) for {icon_name}"
              except Exception as e:
                  return f"Error for {icon_name}: {e}"

          # Use thread pool to parallelize downloads
          with ThreadPoolExecutor(max_workers=100) as executor:
              futures = {executor.submit(download_icon, icon): icon for icon in icons}
              for future in as_completed(futures):
                  print(future.result())
          EOF
      
      - name: Commit and push changes
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@github.com"
          git config pull.rebase true   # rebase
          git add data/
          git commit -m "Updated Static Data" || echo "No changes to commit"
          git pull || echo "No changes to pull"
          git push || echo "No changes to push"
